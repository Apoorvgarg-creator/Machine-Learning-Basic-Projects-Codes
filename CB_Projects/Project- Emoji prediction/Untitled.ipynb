{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emoji Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step-1 get the emoji package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in /Users/apoorvgarg/opt/anaconda3/lib/python3.8/site-packages (0.6.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emoji dictionary\n",
    "# emoji.EMOJI_UNICODE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dictionary = {\n",
    "    \"0\":'\\u2764\\uFE0F',\n",
    "    \"1\":':baseball:',\n",
    "    \"2\":':grinning_face_with_big_eyes:',\n",
    "    \"3\":':disappointed_face:',\n",
    "    \"4\":\":fork_and_knife:\",\n",
    "    \"5\":\":hundred_points:\",\n",
    "    \"6\":\":fire:\",\n",
    "    \"7\":\":face_blowing_a_kiss:\",\n",
    "    \"8\":\":chestnut:\",\n",
    "    \"9\":\":flexed_biceps:\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ù§Ô∏è\n",
      "‚öæ\n",
      "üòÉ\n",
      "üòû\n",
      "üç¥\n",
      "üíØ\n",
      "üî•\n",
      "üòò\n",
      "üå∞\n",
      "üí™\n"
     ]
    }
   ],
   "source": [
    "for e in emoji_dictionary.values():\n",
    "    print(emoji.emojize(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step-2 Processing a custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_emoji.csv',header=None)\n",
    "test = pd.read_csv('test_emoji.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[0]\n",
    "X_test = test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train[1]\n",
    "Y_test = test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "never talk to me again üòû\n",
      "I am proud of your achievements üòÉ\n",
      "It is the worst day in my life üòû\n",
      "Miss you so much ‚ù§Ô∏è\n",
      "food is life üç¥\n",
      "I love you mum ‚ù§Ô∏è\n",
      "Stop saying bullshit üòû\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for y in Y_train[:7]:\n",
    "    print(X_train[i],emoji.emojize(emoji_dictionary[str(y)]))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step-3 Getting the glove vectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('glove.6B.50d.txt',encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:],dtype='float')\n",
    "    embeddings_index[word] = coefs\n",
    "\n",
    "f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.4295e-01, -4.2946e-01, -5.4277e-01, -1.0307e+00,  1.2056e+00,\n",
       "       -2.7174e-01, -6.3561e-01, -1.5065e-02,  3.7856e-01,  4.6474e-02,\n",
       "       -1.3102e-01,  6.0500e-01,  1.6391e+00,  2.3940e-01,  1.2128e+00,\n",
       "        8.3178e-01,  7.3893e-01,  1.5200e-01, -1.4175e-01, -8.8384e-01,\n",
       "        2.0829e-02, -3.2545e-01,  1.8035e+00,  1.0045e+00,  5.8484e-01,\n",
       "       -6.2031e-01, -4.3296e-01,  2.3562e-01,  1.3027e+00, -8.1264e-01,\n",
       "        2.3158e+00,  1.1030e+00, -6.0608e-01,  1.0101e+00, -2.2426e-01,\n",
       "        1.8908e-02, -1.0931e-01,  3.8350e-01,  7.7362e-01, -8.1927e-02,\n",
       "       -3.4040e-01, -1.5143e-03, -5.6640e-02,  8.7359e-01,  1.4805e+00,\n",
       "        6.9421e-01, -3.0966e-01, -9.0826e-01,  3.7277e-03,  8.4550e-01])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index['eat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step-4 Converting Sentences into Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding layer output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_output(X):\n",
    "    maxLen = 10\n",
    "    emb_dim = 50\n",
    "    embedding_out = np.zeros((X.shape[0],maxLen,emb_dim))\n",
    "    for ix in range(X.shape[0]):\n",
    "         X[ix] = X[ix].split()\n",
    "         for ij in range(len(X[ix])):\n",
    "            # Go to every word in the current (ix) sentence\n",
    "            embedding_out[ix][ij] = embeddings_index[X[ix][ij].lower()]\n",
    "            \n",
    "    return embedding_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-39578210305a>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[ix] = X[ix].split()\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix_train = embedding_output(X_train)\n",
    "embedding_matrix_test = embedding_output(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['never', 'talk', 'to', 'me', 'again']\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])\n",
    "print(len(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 10, 50)\n",
      "(56, 10, 50)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix_train.shape)\n",
    "print(embedding_matrix_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Step-5 Define the RNN/LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import LSTM,Dense,Softmax,Dropout,Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 10, 64)            29440     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 62,789\n",
      "Trainable params: 62,789\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64,input_shape=(10,50),return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64,return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 5)\n",
      "[0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "Y_train = to_categorical(Y_train,num_classes=5)\n",
    "Y_test = to_categorical(test[1],num_classes=5)\n",
    "\n",
    "print(Y_train.shape)\n",
    "print(Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0337 - accuracy: 1.0000\n",
      "Epoch 00001: val_loss improved from inf to 1.59217, saving model to best_model.h5\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0413 - accuracy: 0.9905 - val_loss: 1.5922 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0692 - accuracy: 0.9844\n",
      "Epoch 00002: val_loss did not improve from 1.59217\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0647 - accuracy: 0.9810 - val_loss: 1.6319 - val_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0265 - accuracy: 1.0000\n",
      "Epoch 00003: val_loss did not improve from 1.59217\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0507 - accuracy: 0.9905 - val_loss: 1.8394 - val_accuracy: 0.5556\n",
      "Epoch 4/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0352 - accuracy: 0.9844\n",
      "Epoch 00004: val_loss did not improve from 1.59217\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0629 - accuracy: 0.9810 - val_loss: 2.0467 - val_accuracy: 0.5556\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint('best_model.h5',monitor='val_loss',verbose=True,save_best_only=True)\n",
    "earlystop = EarlyStopping(monitor='val_accuracy',patience=3)\n",
    "hist = model.fit(embedding_matrix_train,Y_train,epochs=100,callbacks=[checkpoint,earlystop],batch_size=64,shuffle=True,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(embedding_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 3 1 0 2 2 1 2 1 2 1 2 0 0 1 3 2 2 3 2 0 0 4 2 0 1 2 0 0 2 0 1 0 2 0 2 2\n",
      " 4 4 2 1 0 0 2 2 0 2 2 0 1 3 0 3 2 2 0]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 2.0324 - accuracy: 0.5179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.0324301719665527, 0.5178571343421936]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(embedding_matrix_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iwanttoeat\n",
      "üç¥\n",
      "üç¥\n",
      "hedidnotanswer\n",
      "üòû\n",
      "üòû\n",
      "hegotaraise\n",
      "üòÉ\n",
      "‚öæ\n",
      "shegotmeapresent\n",
      "‚ù§Ô∏è\n",
      "‚ù§Ô∏è\n",
      "hahahaitwassofunny\n",
      "üòÉ\n",
      "üòÉ\n",
      "heisagoodfriend\n",
      "‚ù§Ô∏è\n",
      "üòÉ\n",
      "Iamupset\n",
      "‚ù§Ô∏è\n",
      "‚öæ\n",
      "Wehadsuchalovelydinnertonight\n",
      "‚ù§Ô∏è\n",
      "üòÉ\n",
      "whereisthefood\n",
      "üç¥\n",
      "‚öæ\n",
      "Stopmakingthisjokehahaha\n",
      "üòÉ\n",
      "üòÉ\n",
      "whereistheball\n",
      "‚öæ\n",
      "‚öæ\n",
      "workishard\n",
      "üòû\n",
      "üòÉ\n",
      "Thisgirlismessingwithme\n",
      "üòû\n",
      "‚ù§Ô∏è\n",
      "areyouserioushaha\n",
      "üòÉ\n",
      "‚ù§Ô∏è\n",
      "Letusgoplaybaseball\n",
      "‚öæ\n",
      "‚öæ\n",
      "Thisstupidgraderisnotworking\n",
      "üòû\n",
      "üòû\n",
      "workishorrible\n",
      "üòû\n",
      "üòÉ\n",
      "Congratulationforhavingababy\n",
      "üòÉ\n",
      "üòÉ\n",
      "stopmessingaround\n",
      "üòû\n",
      "üòû\n",
      "anysuggestionsfordinner\n",
      "üç¥\n",
      "üòÉ\n",
      "Ilovetakingbreaks\n",
      "‚ù§Ô∏è\n",
      "‚ù§Ô∏è\n",
      "youbrightenmyday\n",
      "üòÉ\n",
      "‚ù§Ô∏è\n",
      "Iboiledrice\n",
      "üç¥\n",
      "üç¥\n",
      "sheisabully\n",
      "üòû\n",
      "üòÉ\n",
      "Whyareyoufeelingbad\n",
      "üòû\n",
      "‚ù§Ô∏è\n",
      "Iamupset\n",
      "üòû\n",
      "‚öæ\n",
      "Iworkedduringmybirthday\n",
      "üòû\n",
      "üòÉ\n",
      "Mygrandmotheristheloveofmylife\n",
      "‚ù§Ô∏è\n",
      "‚ù§Ô∏è\n",
      "enjoyyourbreak\n",
      "üòÉ\n",
      "‚ù§Ô∏è\n",
      "valentinedayisnear\n",
      "‚ù§Ô∏è\n",
      "üòÉ\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    print(''.join(X_test[i]))\n",
    "    print(emoji.emojize(emoji_dictionary[str(np.argmax(Y_test[i]))]))\n",
    "    print(emoji.emojize(emoji_dictionary[str(pred[i])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
