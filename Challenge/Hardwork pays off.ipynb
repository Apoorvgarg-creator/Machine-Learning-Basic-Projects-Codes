{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Challenge - Hardwork pays off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data preparation\n",
    "- download\n",
    "- load\n",
    "- normalise\n",
    "- visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load the csv\n",
    "X = pd.read_csv(\"Training Data_Hard/Linear_X_Train.csv\")\n",
    "y = pd.read_csv(\"Training Data_Hard/Linear_Y_Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Normalise the data\n",
    "X = X.reshape((-1,))\n",
    "y = y.reshape((-1,))\n",
    "mean = X.mean()\n",
    "std = X.std()\n",
    "print(mean,std)\n",
    "# since std is nearly 1 that shows the data is normalised\n",
    "X = (X-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn\")\n",
    "plt.scatter(X,y,label=\"Train\",color=\"orange\")\n",
    "plt.title(\" Hardwork vs Performance\")\n",
    "plt.xlabel(\"hardwork\")\n",
    "plt.ylabel(\"Performance\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Gradient descent\n",
    "--> with the help of gradient descent we find that value of theta that gives minimum error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def hypothesis(x,theta):\n",
    "    # theta = [theta0, theta1]\n",
    "    y_ = theta[0] + theta[1]*x\n",
    "    return y_\n",
    "\n",
    "def gradient(X,Y,theta):\n",
    "    m=X.shape[0]\n",
    "    grad = np.zeros((2,))\n",
    "    for i in range(m):\n",
    "        x = X[i]\n",
    "        y_= hypothesis(x,theta)\n",
    "        y = Y[i]\n",
    "        \n",
    "        grad[0] += (y_ - y)\n",
    "        grad[1] += (y_ - y)*x\n",
    "    return grad/m\n",
    "\n",
    "def error(X,Y,theta):\n",
    "    m = X.shape[0]\n",
    "    total_error = 0.0\n",
    "    for i in range(m):\n",
    "        y_ = hypothesis(X[i],theta)\n",
    "        total_error += (y_ - Y[i])**2\n",
    "\n",
    "    return (total_error/m)\n",
    "\n",
    "def gradient_descent(X,Y,max_steps=100,learning_rate = 0.1):\n",
    "    theta =np.zeros((2,))\n",
    "    theta_list = []\n",
    "    error_list = []\n",
    "    for i in range(max_steps):\n",
    "        grad = gradient(X,Y,theta)\n",
    "        e = error(X,Y,theta)\n",
    "        theta[0] = theta[0] - learning_rate*grad[0]\n",
    "        theta[1] = theta[1] - learning_rate*grad[1]\n",
    "\n",
    "        theta_list.append((theta[0],theta[1]))\n",
    "        error_list.append(e)\n",
    "\n",
    "    return theta,error_list,theta_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Ot, el, tl = gradient_descent(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(Ot)\n",
    "plt.plot(el)\n",
    "plt.title('Error Function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Prediction and best line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_ = hypothesis(X,Ot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(X,y,color=\"red\",label=\"Actual\")\n",
    "plt.plot(X,y_,color=\"orange\",label=\"Predicted\")\n",
    "plt.xlabel(\"Hardwork\")\n",
    "plt.ylabel(\"Performance\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"Test Cases/Linear_X_Test.csv\").values\n",
    "Y_test = hypothesis(X_test,Ot)\n",
    "y_test = pd.DataFrame(data=Y_test,columns=[\"y\"])\n",
    "\n",
    "y_test.to_csv(\"Ypredtest1.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compute score\n",
    "score : R2(R-squared) or Coefficient of determination"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def r2_score(y_, y):\n",
    "    term2 = sum((y_ - y)**2)\n",
    "    term3 = sum((y-y.mean())**2)\n",
    "    score = (1 - term2/term3)*100\n",
    "    return score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "r2_score(y_,y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualising loss function, gradient descent and theta update"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Loss function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "theta = Ot\n",
    "theta"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "T0 = np.arange(-40,40,1)\n",
    "T1 = np.arange(40,120,1)\n",
    "T0,T1 = np.meshgrid(T0,T1)\n",
    "J = np.zeros(T0.shape)\n",
    "for i in range(J.shape[0]):\n",
    "    for j in range(J.shape[1]):\n",
    "        y_ = T1[i,j]*X + T0[i,j]\n",
    "        J[i,j] =np.sum((y-y_)**2)/y.shape[0]\n",
    "# print(T0,T1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# SURFACE PLOT\n",
    "fig = plt.figure()\n",
    "axes = fig.gca(projection = '3d')\n",
    "axes.plot_surface(T0,T1,J,cmap=\"rainbow\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# CONTOUR PLOT\n",
    "fig = plt.figure()\n",
    "axes = fig.gca(projection = '3d')\n",
    "axes.contour(T0,T1,J,cmap=\"rainbow\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.Plot Gradient descent"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## --> Plot Update theta"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "theta_list = np.array(tl)  # Stores how theta was changing every time\n",
    "plt.plot(theta_list[:,0],label=\"Theta0\")\n",
    "plt.plot(theta_list[:,1],label=\"Theta1\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Trajectory taced by theta updates in the loss function\n",
    "fig = plt.figure()\n",
    "axes = fig.gca(projection = '3d')\n",
    "axes.plot_surface(T0,T1,J,cmap=\"rainbow\")\n",
    "axes.scatter(theta_list[:,0],theta_list[:,1],el)\n",
    "# axes.scatter(theta_list[:,1],label=\"Theta1\")\n",
    "# plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "axes = fig.gca(projection = '3d')\n",
    "axes.contour(T0,T1,J,cmap=\"rainbow\")\n",
    "axes.scatter(theta_list[:,0],theta_list[:,1],el)\n",
    "# axes.scatter(theta_list[:,1],label=\"Theta1\")\n",
    "# plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2d contour plot -->\n",
    "\n",
    "plt.contour(T0,T1,J,cmap=\"rainbow\")\n",
    "plt.scatter(theta_list[:,0],theta_list[:,1])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.save(\"Thetalist.npy\",theta_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}