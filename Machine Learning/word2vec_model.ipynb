{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Word to Vector model\n",
    "- Using Pre-trained WORD VECTORS\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word2Vec Model\n",
    "- Word2vec google's pretrained model\n",
    "- contains vector representation of 50 billion words\n",
    "- words which are similar in context have similar vectors\n",
    "- Distance/Similarity between two words can be measured using cosine distance\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Application\n",
    "- Text Similarity\n",
    "- Language translation\n",
    "- finding odd words\n",
    "- word analogies"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word embeddings\n",
    "- Word embedding are numerical representation of words, in the form of vectors\n",
    "- Word2Vec Model represents each word as 300 dimensional vector\n",
    "- In this tutorial we are going to use pre-trained word2vec model\n",
    "- model size is around 1.5 GB\n",
    "- we will work using gensim, which is a popular NLP package\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Genism's word2vec model provides optimum implementation of\n",
    "- 1) ***CBOW***(Bag of words) model\n",
    "- 2) ***SkipGram*** model\n",
    "\n",
    "\n",
    "Paper 1 -->\n",
    "\n",
    "Paper 2 -->"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word2Vec model using gensim\n",
    "-"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Code\n",
    "#### Lode Word2Vec model\n",
    "***KeyedVectors*** - This object essentially contains the mapping between words and embeddings.\n",
    "After training, it can be used directly to query those embeddings in various ways"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format(fname='GoogleNews-vectors-negative300.bin',binary=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "v_apple = word_vectors['apple']\n",
    "v_mango = word_vectors['mango']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.57518554]], dtype=float32)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Capital letter and small letter means different, since model is based on that\n",
    "cosine_similarity([v_apple],[v_mango])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Question - Answering - Find the odd one out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "input_1 = ['apple','mango','juice','party','orange']\n",
    "input_2 = ['music','dance','sleep','dancer','food']\n",
    "input_3 = ['match','player','football','cricket',\"dancer\"]\n",
    "input_4 = ['india','paris','russia','france','germany']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def odd_one_out(words):\n",
    "    \"\"\" Accepts a list of words and returns the odd word\"\"\"\n",
    "\n",
    "    # Generate all word embedding for the given text\n",
    "    all_word_vectors = [word_vectors[w] for w in words]\n",
    "    print(len(all_word_vectors))\n",
    "\n",
    "    avg_vector = np.mean(all_word_vectors,axis=0)  # Shape (300,)\n",
    "    # iterate over every word and find similarity\n",
    "    odd_one_out = None\n",
    "    min_sim = 1.0 # very high value\n",
    "    for w in words:\n",
    "        sim = cosine_similarity([word_vectors[w]],[avg_vector])\n",
    "        if sim < min_sim:\n",
    "            min_sim = sim\n",
    "            odd_one_out = w\n",
    "\n",
    "        print(\"Similarity btw %s and avg vector is %0.2f\"%(w,sim))\n",
    "    return odd_one_out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Similarity btw apple and avg vector is 0.78\n",
      "Similarity btw mango and avg vector is 0.76\n",
      "Similarity btw juice and avg vector is 0.71\n",
      "Similarity btw party and avg vector is 0.36\n",
      "Similarity btw orange and avg vector is 0.65\n"
     ]
    },
    {
     "data": {
      "text/plain": "'party'"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_one_out(input_1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filename ='/odd/test.csv'\n",
    "with open(filename,'r') as f:\n",
    "    text = f.read()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Word Analogies Task\n",
    "- In the word analogy task, we compute the sentence \"a is to b as c is to __\". An example is 'man is to woman as king is\n",
    "to queen\". In detail, we are trying to find a word d, such that the associated word vector ea, eb ec, ed are related in\n",
    "the following manner: eb-ea-ed-ec.We will measure the similarity betweem eb-ea and ed-ec using cosine similarity."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# word_vectors.vocab"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def predict_words(a,b,c,word_vectors):\n",
    "    \"\"\"Accepts a triad of words,a,b,a and returns d such that a is to b : c is to d\"\"\"\n",
    "    a, b, c = a.lower(), b.lower(), c.lower()\n",
    "    # similarity |b-a|=|d-c| should be max\n",
    "    max_sim = -100\n",
    "    d = None\n",
    "    words = word_vectors.vocab.keys()\n",
    "    wa, wb, wc = word_vectors[a], word_vectors[b], word_vectors[c]\n",
    "\n",
    "    for w in words:\n",
    "        if w in [a,b,c]: continue\n",
    "\n",
    "        wv = word_vectors[w]\n",
    "        sim = cosine_similarity([wb-wa],[wv-wc])\n",
    "\n",
    "        if sim > max_sim:\n",
    "            max_sim = sim\n",
    "            d = w\n",
    "\n",
    "\n",
    "    return d"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-25-6b602634e7ab>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mtriad_2\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m\"man\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"woman\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"prince\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mpredict_words\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtriad_2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mword_vectors\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-24-963df99286e7>\u001B[0m in \u001B[0;36mpredict_words\u001B[0;34m(a, b, c, word_vectors)\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m         \u001B[0mwv\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mword_vectors\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mw\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 14\u001B[0;31m         \u001B[0msim\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcosine_similarity\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mwb\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0mwa\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mwv\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0mwc\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     15\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0msim\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0mmax_sim\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/CB_lecture/venv/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001B[0m in \u001B[0;36mcosine_similarity\u001B[0;34m(X, Y, dense_output)\u001B[0m\n\u001B[1;32m   1177\u001B[0m     \u001B[0;31m# to avoid recursive import\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1178\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1179\u001B[0;31m     \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcheck_pairwise_arrays\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1180\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1181\u001B[0m     \u001B[0mX_normalized\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnormalize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/CB_lecture/venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36minner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     70\u001B[0m                           FutureWarning)\n\u001B[1;32m     71\u001B[0m         \u001B[0mkwargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0marg\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 72\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     73\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0minner_f\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     74\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/CB_lecture/venv/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001B[0m in \u001B[0;36mcheck_pairwise_arrays\u001B[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001B[0m\n\u001B[1;32m    146\u001B[0m                         \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mforce_all_finite\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mforce_all_finite\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    147\u001B[0m                         estimator=estimator)\n\u001B[0;32m--> 148\u001B[0;31m         Y = check_array(Y, accept_sparse=accept_sparse, dtype=dtype,\n\u001B[0m\u001B[1;32m    149\u001B[0m                         \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mforce_all_finite\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mforce_all_finite\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    150\u001B[0m                         estimator=estimator)\n",
      "\u001B[0;32m~/PycharmProjects/CB_lecture/venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36minner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     70\u001B[0m                           FutureWarning)\n\u001B[1;32m     71\u001B[0m         \u001B[0mkwargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0marg\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 72\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     73\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0minner_f\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     74\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/CB_lecture/venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001B[0m\n\u001B[1;32m    642\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    643\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mforce_all_finite\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 644\u001B[0;31m             _assert_all_finite(array,\n\u001B[0m\u001B[1;32m    645\u001B[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001B[1;32m    646\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/CB_lecture/venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36m_assert_all_finite\u001B[0;34m(X, allow_nan, msg_dtype)\u001B[0m\n\u001B[1;32m     87\u001B[0m     \u001B[0;31m# safely to reduce dtype induced overflows.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     88\u001B[0m     \u001B[0mis_float\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkind\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m'fc'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 89\u001B[0;31m     \u001B[0;32mif\u001B[0m \u001B[0mis_float\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0misfinite\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_safe_accumulator_op\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msum\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     90\u001B[0m         \u001B[0;32mpass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     91\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mis_float\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/CB_lecture/venv/lib/python3.8/site-packages/sklearn/utils/extmath.py\u001B[0m in \u001B[0;36m_safe_accumulator_op\u001B[0;34m(op, x, *args, **kwargs)\u001B[0m\n\u001B[1;32m    707\u001B[0m     \"\"\"\n\u001B[1;32m    708\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0missubdtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloating\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitemsize\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0;36m8\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 709\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat64\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    710\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    711\u001B[0m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<__array_function__ internals>\u001B[0m in \u001B[0;36msum\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/CB_lecture/venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001B[0m in \u001B[0;36msum\u001B[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001B[0m\n\u001B[1;32m   2090\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2091\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2092\u001B[0;31m \u001B[0;34m@\u001B[0m\u001B[0marray_function_dispatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_sum_dispatcher\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2093\u001B[0m def sum(a, axis=None, dtype=None, out=None, keepdims=np._NoValue,\n\u001B[1;32m   2094\u001B[0m         initial=np._NoValue, where=np._NoValue):\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "triad_2 = (\"man\",\"woman\",\"prince\")\n",
    "predict_words(*(triad_2),word_vectors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using most similar method\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-26-32fa07966c04>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mword_vectors\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmost_similar\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpositive\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'woman'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m'king'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mnegative\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'man'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mtopn\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/PycharmProjects/CB_lecture/venv/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001B[0m in \u001B[0;36mmost_similar\u001B[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001B[0m\n\u001B[1;32m    529\u001B[0m             \u001B[0mnegative\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    530\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 531\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minit_sims\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    532\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    533\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpositive\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstring_types\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mnegative\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/CB_lecture/venv/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001B[0m in \u001B[0;36minit_sims\u001B[0;34m(self, replace)\u001B[0m\n\u001B[1;32m   1352\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'vectors_norm'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mreplace\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1353\u001B[0m             \u001B[0mlogger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"precomputing L2-norms of word weight vectors\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1354\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvectors_norm\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_l2_norm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvectors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreplace\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mreplace\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1355\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1356\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mrelative_cosine_similarity\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mwa\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mwb\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtopn\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/CB_lecture/venv/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001B[0m in \u001B[0;36m_l2_norm\u001B[0;34m(m, replace)\u001B[0m\n\u001B[1;32m   2382\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2383\u001B[0m     \"\"\"\n\u001B[0;32m-> 2384\u001B[0;31m     \u001B[0mdist\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msqrt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mm\u001B[0m \u001B[0;34m**\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m...\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnewaxis\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2385\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mreplace\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2386\u001B[0m         \u001B[0mm\u001B[0m \u001B[0;34m/=\u001B[0m \u001B[0mdist\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "word_vectors.most_similar(positive=['woman','king'],negative=['man'],topn=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}